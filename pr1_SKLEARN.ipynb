{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db089d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a981fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.dat', 'r') as fh:\n",
    "    train = fh.readlines()\n",
    "\n",
    "with open('test.dat', 'r') as fh:\n",
    "    test = fh.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e120bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ytrain, = labels for the training set\n",
    "ytr = [int(p.split('\\t')[0]) for p in train]\n",
    "tr = [p.split('\\t')[1].strip() for p in train]\n",
    "te = [p.strip() for p in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d69c7bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def kmer(p, k=2):\n",
    "    return [p[i:i+k] for i in range(0, len(p)-k+1)]\n",
    "\n",
    "def kmers(p, k=2):\n",
    "    els = []\n",
    "    for i in range(1,k):\n",
    "        els.extend(kmer(p, k=i))\n",
    "    return els"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a50ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = [kmers(p, k=3) for p in tr]\n",
    "te = [kmers(p, k=3) for p in te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b05a4d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assign IDS and create dictionary. each peptide is represented as a vector with 436 features\n",
    "# Now we put the count in that vector of how many times we find a particular feature\n",
    "# Dense is bad, as it keeps all features including counts of 0\n",
    "# Sparse is much faster as it removes the 0 values from the vector features\n",
    "\n",
    "mp = {} # dictionary\n",
    "for p in tr+te:\n",
    "    for e in p:\n",
    "        if e not in mp:\n",
    "            mp[e] = len(mp)\n",
    "\n",
    "len(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95ef84da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 3., 1., 1., 2., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each of the peptides we create a count of their features. by default it is dense, but we can do work to remove the 0's to make it sparse.\n",
    "\n",
    "# transforming peptide to vector\n",
    "def dense(p):\n",
    "    x  = np.zeros(len(mp))\n",
    "    for e in p:\n",
    "        x[mp[e]] += 1\n",
    "    return x\n",
    "\n",
    "dense(tr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aded20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse dataset from all the peptides. # csr matrix only stores non-zeros. it does not store the zeros\n",
    "def sparse(ds):\n",
    "    nrows = len(ds) # number of rows\n",
    "    ptr = np.zeros(nrows+1, dtype=int) #pointer array\n",
    "    nnz = 0 # number of non-zeros\n",
    "    for i, p in enumerate(ds): # figuring out size of each row\n",
    "        ps = set(p)\n",
    "        nnz += len(ps)\n",
    "        ptr[i+1] = nnz # populate pointers of where the row starts and ends\n",
    "    ind = np.zeros(nnz, dtype=int)\n",
    "    val = np.zeros(nnz, dtype=float)\n",
    "    nnz = 0\n",
    "    for p in ds:\n",
    "        ct = Counter(p).most_common()\n",
    "        for e, c in ct:\n",
    "            val[nnz] = c\n",
    "            ind[nnz] = mp[e]\n",
    "            nnz += 1\n",
    "    return csr_matrix((val, ind, ptr), shape=(nrows, len(mp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de0410a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sptr = sparse(tr)\n",
    "spte = sparse(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f663703b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1566"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sptr.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0542041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sptr[0:783].toarray()\n",
    "#X_test = sptr[782:1565].toarray()\n",
    "y_train = ytr[0:783]\n",
    "#y_test = ytr[782:1565]\n",
    "#len(y_test)\n",
    "X_test = spte.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8852b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = MLPClassifier(random_state=1, max_iter=100).fit(X_train, y_train) # X_train, y_train\n",
    "#predic = clf.predict(X_test) # X_test\n",
    "#clf.score(X_test, y_test) # X_test, y_test\n",
    "#mcc = matthews_corrcoef(y_test, predic) # y_test, predic\n",
    "#print(mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a73d1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "sptr_over, ytr_over = oversample.fit_resample(X_train, y_train)\n",
    "clf_over = MLPClassifier(random_state=1, max_iter=100).fit(sptr_over, ytr_over)\n",
    "predic_over = clf_over.predict(X_test)\n",
    "#mcc_over = matthews_corrcoef(y_test, predic_over)\n",
    "#print(mcc_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0383ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptronPredictions = clf_over.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e08a381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", 'w') as fh:\n",
    "    fh.write(\"\\n\".join(map(str, perceptronPredictions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
